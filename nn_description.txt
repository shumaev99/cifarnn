Нейронная сеть для классификации изображений

Архитектура:
(32x32x3) -> Convolution -> (32x32x32) -> Convolution -> (32x32x32) -> Maxpool -> (16x16x32) -> Dropout -> Convolution -> (16x16x64) -> Convolution -> (16x16x64) -> Maxpool -> (8x8x64) -> Dropout -> Flatten -> (4096) -> Dense -> (64) -> Dropout -> Dense -> (10)
Convolution: конволюционный слой, квинтэссенция нейронки. Позволяет находить небольшие паттерны в картинке.
Maxpool: для уменьшения размера и консолидации. После конволюционного слоя выбирает только те локации, где обнаруженные паттерны наиболее ярко выражены.
Dropout: выбрасывает половину связей в случайном порядке. Нужен, чтобы нейронка не находила локальные минимумы и тренировалась лучше.
Flatten: выпрямление данных, для подготовки к выводу
Dense: полностью соединенный слой, который собственно и выводит вероятности для всех классов.

Метод тренировки:
60000 картинок всего, из них 48000 на тренировку, остальные 12000 для валидации. Размер батча 256 картинок, оптимизатор Адам (дефолтные настройки), лосс-функция (потери) --- кроссэнтропия (-y*log(p)-(1-y)*log(1-p), y: истинное значение для каждого класса 0 или 1, p: вероятность предсказанная нейронкой). Тренируем 30 эпох, то есть проходимся по датасету 30 раз (поправь здесь, если хочешь больше).

Использован Керас (Keras with Tensorflow backend) последней версии
